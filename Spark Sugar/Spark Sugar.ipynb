{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataTypes in PySpark:**  \n",
    "\n",
    "RDD:\n",
    "* Records\n",
    "\n",
    "DataFrames:\n",
    "* Rows\n",
    "* Columns\n",
    "\n",
    "Groupby:\n",
    "* Groups\n",
    "\n",
    "DataSets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joins:**  \n",
    "*multiple joins*  \n",
    "You can join multiple dataframes in one chained function.\n",
    "\n",
    "```python\n",
    ">>> df = sc.sql.createDataFrame([('Alice', 2), ('Bob', 5)], ['name','age'])\n",
    ">>> df_2 = sc.sql.createDataFrame([('Alice', 'female'), ('Bob', 'male')], ['name','gender'])\n",
    ">>> df_3 = sc.sql.createDataFrame([('female', 'pink'), ('male', 'blue')], ['gender','color'])\n",
    ">>> df.join(df_2, 'name')\\\n",
    "...   .join(df_3, 'gender')\n",
    "...   .collect()\n",
    "[\n",
    "    Row(struct=Row(name=u'Alice', gender=u'female', age=2)), \n",
    "    Row(struct=Row(name=u'Bob', gender=u'male', age=5))\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.struct in PySpark:**  \n",
    "`pyspark.sql.functions.`**`struct`**`(*cols)`\n",
    "\n",
    "Creates a new struct column.  \n",
    "**Parameters:**\t**cols** â€“ list of column names (string) or list of **Column** expressions\n",
    "\n",
    "Example:\n",
    "```python\n",
    ">>> df = sc.sql.createDataFrame([('Alice', 2), ('Bob', 5)], ['name','age'])\n",
    "\n",
    ">>> df.select(struct('age', 'name').alias(\"struct\")).collect()\n",
    "[\n",
    "    Row(struct=Row(age=2, name=u'Alice')), \n",
    "    Row(struct=Row(age=5, name=u'Bob'))\n",
    "]\n",
    "\n",
    ">>> df.select(struct([df.age, df.name]).alias(\"struct\")).collect()\n",
    "[\n",
    "    Row(struct=Row(age=2, name=u'Alice')), \n",
    "    Row(struct=Row(age=5, name=u'Bob'))\n",
    "]\n",
    "```\n",
    "\n",
    "Use cases:\n",
    "1. When you use `groupBy`, it drop any columns you're not grouping by or aggregating on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**F.coalesce in PySpark:**  \n",
    "`pyspark.sql.functions.`**`coalesce`**`(*cols)`\n",
    "\n",
    "Returns the first column that is not null.\n",
    "\n",
    "Example:\n",
    "```python\n",
    ">>> cDf = sc.sql.createDataFrame([(None, None), (1, None), (None, 2)], (\"a\", \"b\"))\n",
    ">>> cDf.show()\n",
    "+----+----+\n",
    "|   a|   b|\n",
    "+----+----+\n",
    "|null|null|\n",
    "|   1|null|\n",
    "|null|   2|\n",
    "+----+----+\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> cDf.select(coalesce(cDf[\"a\"], cDf[\"b\"])).show()\n",
    "+--------------+\n",
    "|coalesce(a, b)|\n",
    "+--------------+\n",
    "|          null|\n",
    "|             1|\n",
    "|             2|\n",
    "+--------------+\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> cDf.select('*', coalesce(cDf[\"a\"], lit(0.0))).show()\n",
    "+----+----+----------------+\n",
    "|   a|   b|coalesce(a, 0.0)|\n",
    "+----+----+----------------+\n",
    "|null|null|             0.0|\n",
    "|   1|null|             1.0|\n",
    "|null|   2|             0.0|\n",
    "+----+----+----------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-dimensional arrays collapsing in DataFrames:**  \n",
    "Calling `F.explode(col)` will flatten all 2-D arrays in `col`.\n",
    "\n",
    "```python\n",
    ">>> df = sc.sql.createDataFrame([(['a'],'a'),\n",
    "...                             (['a', 'b'],'a'),\n",
    "...                             (['c'],'b'),\n",
    "...                             (['d', 'e'],'b')],\n",
    "...                             ['arrays', 'group'])\n",
    ">>> df = df.withColumn('arrays', F.explode('arrays'))\n",
    ">>> df.groupBy('group').agg(F.collect_list('arrays').alias('arrays')).collect()\n",
    "[Row(group=u'b', arrays=[u'c', u'd', u'e']), Row(group=u'a', arrays=[u'a', u'a', u'b'])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Python Functions**\n",
    "* Functions are just variables in python. By writing it like this you save space and complexity as opposed to doing it in-line.\n",
    "\n",
    "```python\n",
    ">>> def derived_session_token_udf():\n",
    ">>>    return F.concat(\n",
    "...        F.col(\"shop_id\").cast(\"string\"), F.lit(\":\"),\n",
    "...        F.col(\"user_token\"), F.lit(\":\"),\n",
    "...        F.col(\"session_token\"), F.lit(\":\"),\n",
    "...        F.year(F.col(timestamp_key)), F.lit(\":\"),\n",
    "...        F.dayofyear(F.col(timestamp_key))\n",
    "...    )\n",
    "\n",
    ">>> new_df = df.withColumn(\"derived_session_token\", derived_session_token_udf())\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
